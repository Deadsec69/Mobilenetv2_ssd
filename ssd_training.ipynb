{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "BatchNormalization._USE_V2_BEHAVIOR = False\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU6 Layer\n",
    "class Relu6(Layer):\n",
    "    ''' ReLU6 Layer.\n",
    "    \n",
    "    Performs ReLU6 activation.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Relu6, self).__init__()\n",
    "        self.relu6 = tf.nn.relu6\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.relu6(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization Layer\n",
    "class BatchNorm(Layer):\n",
    "    ''' Batch Normalization Layer.\n",
    "        \n",
    "    Performs Batch Normalization.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, scale=True, center=True):\n",
    "        super(BatchNorm, self).__init__()        \n",
    "        #self.bn = tf.keras.layers.BatchNormalization(scale=scale, center=center, trainable=True)\n",
    "        self.bn = BatchNormalization(scale=scale, center=center, trainable=True)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        #print(training)\n",
    "        return self.bn(inputs, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolution\n",
    "class Convolution2D(Layer):\n",
    "    '''Performs 2D Convolution without any activation.\n",
    "    \n",
    "    Used for 2D convolution including 1x1 convolution blocks.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, filters, kernel_size, strides, padding):\n",
    "        super(Convolution2D, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                            strides = strides, padding = padding)\n",
    "        self.bn = BatchNorm()\n",
    "    def call(self, inputs,training=False):\n",
    "        \n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x,training)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolution, RELU6\n",
    "class Convolution2D_RELU6(Layer):\n",
    "    '''Performs 2D Convolution with RELU6 activation.\n",
    "    \n",
    "    2D Convolution with RELU6 activation.\n",
    "    Used mainly for residual blocks in Mobilenet V2.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, filters, kernel_size, strides, padding):\n",
    "        super(Convolution2D_RELU6, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                            strides = strides, padding = padding)\n",
    "        \n",
    "\n",
    "        self.act = Relu6()\n",
    "        \n",
    "    def call(self, inputs,training=None):\n",
    "        \n",
    "        x = self.conv(inputs)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Pooling Layer\n",
    "class AveragePooling(Layer):\n",
    "    '''Average Pooling Layer.\n",
    "    \n",
    "    Used to perform Average pooling operation over the input tensors.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, pool_size):\n",
    "        super(AveragePooling, self).__init__()\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=pool_size, padding=\"SAME\")\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.avgpool(inputs)\n",
    "         \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    '''Dense Layer.\n",
    "    \n",
    "    Fully Connected Layer.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(units=units,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.dense(inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    '''Flatten Layer.\n",
    "    \n",
    "    Used to flatten outputs after Convolutions.\n",
    "    Dense Layer does not automatically manages the flatten.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.flatten(inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Convolution\n",
    "class DepthwiseConvolution(Layer):\n",
    "    ''' Depthwise Convolution Layer.\n",
    "    \n",
    "    Performs Depthwise Convolution with Batch Norm\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, kernel_size = 3, strides = 1, padding = \"SAME\"):\n",
    "        super(DepthwiseConvolution, self).__init__()\n",
    "        self.dconv = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides,\n",
    "                                     depth_multiplier=1,\n",
    "                                     padding=padding)\n",
    "        self.bn = BatchNorm()\n",
    "    \n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "        x = self.dconv(inputs)\n",
    "        x = self.bn(x,training)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separable Convolution\n",
    "class SeparableConvolution(Layer):\n",
    "    ''' Separable Convolution Layer.\n",
    "    \n",
    "    Performs Separable Convolution.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, filters = 32, kernel_size = 3, strides = 1, padding = \"SAME\", \n",
    "                 depth_multiplier = 1):\n",
    "        super(SeparableConvolution, self).__init__()\n",
    "        self.sconv = tf.keras.layers.SeparableConv2D(filters,kernel_size, strides=strides,\n",
    "                                     depth_multiplier=depth_multiplier,\n",
    "                                     padding=padding)\n",
    "        self.bn = BatchNorm()\n",
    "        self.act = Relu6()\n",
    "    \n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "        \n",
    "        x = self.sconv(inputs)\n",
    "        x = self.bn(x,training)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Normalization\n",
    "class GroupNorm(Layer):\n",
    "    ''' Group Normalization Layer.\n",
    "    \n",
    "    Divides the channels of your inputs into smaller sub groups \n",
    "    and normalizes these values based on their mean and variance.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, groups=5, axis=3):\n",
    "        super(GroupNorm, self).__init__()\n",
    "        self.gnorm = tfa.layers.GroupNormalization(groups=groups, axis=axis)\n",
    "    \n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.gnorm(inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer to perform Residual Addition for Mobilenet V2\n",
    "class AdditionLayer(Layer):\n",
    "    ''' Addition Layer.\n",
    "    \n",
    "    Adds Output of Expansion block to inputs in case of Stride 1 Blocks.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(AdditionLayer, self).__init__()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "    \n",
    "\n",
    "    def call(self, input1, input2):\n",
    "        return self.add([input1, input2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Average Pooling Layer\n",
    "class GlobalAveragePooling(Layer):\n",
    "    '''Global Average Pooling Layer.\n",
    "    \n",
    "    Used to perform Global Average pooling operation over the input tensors.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GlobalAveragePooling, self).__init__()\n",
    "        \n",
    "        self.gpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.gpool(inputs)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _split_divisible(num, num_ways, divisible_by=8):\n",
    "    \"\"\"Evenly splits num, num_ways so each piece is a multiple of divisible_by.\"\"\"\n",
    "    assert num % divisible_by == 0\n",
    "    assert num / num_ways >= divisible_by\n",
    "    # Note: want to round down, we adjust each split to match the total.\n",
    "    base = num // num_ways // divisible_by * divisible_by\n",
    "    result = []\n",
    "    accumulated = 0\n",
    "    for i in range(num_ways):\n",
    "        r = base\n",
    "        while accumulated + r < num * (i + 1) / num_ways:\n",
    "          r += divisible_by\n",
    "        result.append(r)\n",
    "        accumulated += r\n",
    "    assert accumulated == num\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _fixed_padding(inputs, kernel_size, rate=1):\n",
    "    \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
    "\n",
    "    Pads the input such that if it was used in a convolution with 'VALID' padding,\n",
    "    the output would have the same dimensions as if the unpadded input was used\n",
    "    in a convolution with 'SAME' padding.\n",
    "\n",
    "    Args:\n",
    "    inputs: A tensor of size [batch, height_in, width_in, channels].\n",
    "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "    rate: An integer, rate for atrous convolution.\n",
    "\n",
    "    Returns:\n",
    "    output: A tensor of size [batch, height_out, width_out, channels] with the\n",
    "      input, either intact (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "    \"\"\"\n",
    "    kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n",
    "                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n",
    "    pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n",
    "    pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n",
    "    pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n",
    "    padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n",
    "                                  [pad_beg[1], pad_end[1]], [0, 0]])\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_input_by_factor(n, divisible_by=8):\n",
    "    return lambda num_inputs, **_: _make_divisible(num_inputs * n, divisible_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandedConvolutionStride1(Layer):\n",
    "    ''' Expanded Convolution Layer.\n",
    "        \n",
    "    Used for Residual blocks of Mobilenet V2 with Stride 1 Blocks.\n",
    "    Input -> Expansion Block + Input -> Output.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_filters, filters, kernel, block_stride=1, padding=\"SAME\", expansion_factor=6):\n",
    "        super(ExpandedConvolutionStride1, self).__init__()\n",
    "        \n",
    "        self.conv1 = Convolution2D_RELU6(input_filters*expansion_factor, (1, 1), 1, padding)\n",
    "        self.dconv1 = DepthwiseConvolution(strides=block_stride)\n",
    "        self.conv2 = Convolution2D(filters, (1, 1), 1, padding)\n",
    "        self.add = AdditionLayer()\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.dconv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.add(x, inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandedConvolutionStride2(Layer):\n",
    "    ''' Expanded Convolution Layer.\n",
    "        \n",
    "    Used for Residual blocks of Mobilenet V2 with Stride 2 Blocks.\n",
    "    Input -> Expansion Block -> Output.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_filters, filters, kernel, block_stride=2, padding=\"SAME\", expansion_factor=6):\n",
    "        super(ExpandedConvolutionStride2, self).__init__()        \n",
    "        \n",
    "        self.conv1 = Convolution2D_RELU6(input_filters*expansion_factor, (1, 1), 1, padding)\n",
    "        self.dconv1 = DepthwiseConvolution(strides=block_stride)\n",
    "        self.conv2 = Convolution2D(filters, (1, 1), 1, padding)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.dconv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandedConvolution(Layer):\n",
    "    ''' Expanded Convolution Layer.\n",
    "        \n",
    "    Used for Residual blocks of Mobilenet V2 with Stride 1 Blocks.\n",
    "    Input -> Expansion Block -> Output.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_filters, filters, kernel, block_stride=1, padding=\"SAME\", expansion_factor=6):\n",
    "        super(ExpandedConvolution, self).__init__()        \n",
    "        \n",
    "        self.dconv1 = DepthwiseConvolution(strides=block_stride)\n",
    "        self.conv2 = Convolution2D(filters, (1, 1), block_stride, padding)\n",
    "        #self.add = AdditionLayer()\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        \n",
    "        x = self.dconv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        #x = self.add(x, inputs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandedConvolutionDiff(Layer):\n",
    "    ''' Expanded Convolution Layer Diff.\n",
    "        \n",
    "    Used for Residual blocks of Mobilenet V2 with Stride 1 blocks with different channels.\n",
    "    Used for other than first bottleneck layer.\n",
    "    Input -> Expansion Block -> Output.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_filters, filters, kernel, block_stride=1, padding=\"SAME\", expansion_factor=6):\n",
    "        super(ExpandedConvolutionDiff, self).__init__()        \n",
    "        \n",
    "        self.conv1 = Convolution2D_RELU6(input_filters*expansion_factor, (1, 1), 1, padding)\n",
    "        self.dconv1 = DepthwiseConvolution(strides=block_stride)\n",
    "        self.conv2 = Convolution2D(filters, (1, 1), block_stride, padding)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.dconv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conff=\"\"\n",
    "\n",
    "\n",
    "def create_conf_head_layers(num_classes):\n",
    "    \"\"\" Create layers for classification\n",
    "    \"\"\"\n",
    "    conf_head_layers = [\n",
    "        [\n",
    "        Convolution2D(6*num_classes, (3, 3), (1, 1), \"SAME\"),\n",
    "        DepthwiseConvolution(kernel_size=3),            # for 15th block\n",
    "        ],\n",
    "        [Convolution2D(6*num_classes, (1, 1), (1, 1), \"SAME\")\n",
    "        ]  # for 19th block\n",
    "    ]\n",
    "\n",
    "    return conf_head_layers\n",
    "\n",
    "\n",
    "def create_loc_head_layers():\n",
    "    \"\"\" Create layers for regression\n",
    "    \"\"\"\n",
    "    loc_head_layers = [\n",
    "        [ \n",
    "        Convolution2D(6*4, (3, 3), (1, 1), \"SAME\"),\n",
    "        DepthwiseConvolution(kernel_size=3),            # for 15th block\n",
    "        ],\n",
    "        [ Convolution2D(6*4, (1, 1), (1, 1), \"SAME\")\n",
    "         ]# for 19th block\n",
    "    ]\n",
    "\n",
    "    return loc_head_layers\n",
    "\n",
    "\n",
    "class MobilenetV2(Model):\n",
    "    ''' Mobilenet V2.\n",
    "        Mobilenet V2 Layer Architecture.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_outputs):\n",
    "        super(MobilenetV2, self).__init__()\n",
    "        self.num_outputs=num_outputs\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(\"dui\")\n",
    "        self.batch_norm = BatchNorm()\n",
    "        self.batch_norm_1 = BatchNorm()\n",
    "        \n",
    "        # Layer - 1, Convolution 2D, 32 Output Channels, \"SAME\" padding\n",
    "        self.conv1 = Convolution2D(32, (3, 3), (2, 2), \"SAME\")\n",
    "        \n",
    "        # Layer - 2, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp1 = ExpandedConvolution(input_filters=32, filters=16, kernel = (3, 3), # Input Channels - 32\n",
    "                                               expansion_factor=1) # Output Channels 16, stride = 1\n",
    "        \n",
    "        # Layer - 3, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp2 = ExpandedConvolutionStride2(input_filters=16, filters=24, kernel = (3, 3), # Input Channels - 16\n",
    "                                               expansion_factor=6) # Output Channels 24, stride = 2\n",
    "        \n",
    "        # Layer - 4, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp3 = ExpandedConvolutionStride1(input_filters=24, filters=24, kernel = (3, 3), # Input Channels - 24\n",
    "                                               expansion_factor=6) # Output Channels 24, stride = 1\n",
    "        \n",
    "        # Layer - 5, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp4 = ExpandedConvolutionStride2(input_filters=24, filters=32, kernel = (3, 3), # Input Channels - 24\n",
    "                                               expansion_factor=6) # Output Channels 32, stride = 2\n",
    "        \n",
    "        # Layer - 6, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp5 = ExpandedConvolutionStride1(input_filters=32, filters=32, kernel = (3, 3), # Input Channels - 32\n",
    "                                               expansion_factor=6) # Output Channels 32, stride = 1\n",
    "        \n",
    "        # Layer - 7, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp6 = ExpandedConvolutionStride1(input_filters=32, filters=32, kernel = (3, 3), # Input Channels - 32\n",
    "                                               expansion_factor=6) # Output Channels 32, stride = 1\n",
    "        \n",
    "        # Layer - 8, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp7 = ExpandedConvolutionStride2(input_filters=32, filters=64, kernel = (3, 3), # Input Channels - 32\n",
    "                                               expansion_factor=6) # Output Channels 64, stride = 2\n",
    "        \n",
    "        # Layer - 9, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp8 = ExpandedConvolutionStride1(input_filters=64, filters=64, kernel = (3, 3), # Input Channels - 64\n",
    "                                               expansion_factor=6) # Output Channels 64, stride = 1\n",
    "        # Layer - 10, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp9 = ExpandedConvolutionStride1(input_filters=64, filters=64, kernel = (3, 3), # Input Channels - 64\n",
    "                                               expansion_factor=6) # Output Channels 64, stride = 1\n",
    "        \n",
    "        # Layer - 11, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp10 = ExpandedConvolutionStride1(input_filters=64, filters=64, kernel = (3, 3), # Input Channels - 64\n",
    "                                               expansion_factor=6) # Output Channels 48, stride = 1\n",
    "        \n",
    "        # Layer - 12, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp11 = ExpandedConvolutionDiff(input_filters=64, filters=96, kernel = (3, 3), # Input Channels - 64\n",
    "                                               expansion_factor=6) # Output Channels 96, stride = 1\n",
    "        \n",
    "        # Layer - 13, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp12 = ExpandedConvolutionStride1(input_filters=96, filters=96, kernel = (3, 3), # Input Channels - 96\n",
    "                                               expansion_factor=6) # Output Channels 64, stride = 1\n",
    "        \n",
    "        # Layer - 14, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp13 = ExpandedConvolutionStride1(input_filters=96, filters=96, kernel = (3, 3), # Input Channels - 96\n",
    "                                               expansion_factor=6) # Output Channels 96, stride = 1\n",
    "        \n",
    "        # Layer - 15, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp14 = ExpandedConvolutionStride2(input_filters=96, filters=160, kernel = (3, 3), # Input Channels - 96\n",
    "                                               expansion_factor=6) # Output Channels 160, stride = 2\n",
    "        \n",
    "        # Layer - 16, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp15 = ExpandedConvolutionStride1(input_filters=160, filters=160, kernel = (3, 3), # Input Channels - 160\n",
    "                                               expansion_factor=6) # Output Channels 160, stride = 1\n",
    "        \n",
    "        # Layer - 17, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp16 = ExpandedConvolutionStride1(input_filters=160, filters=160, kernel = (3, 3), # Input Channels - 160\n",
    "                                               expansion_factor=6) # Output Channels 160, stride = 1\n",
    "        \n",
    "        # Layer - 18, Inverted Residuals and Linear Bottlenecks\n",
    "        self.exp17 = ExpandedConvolutionDiff(input_filters=160, filters=320, kernel = (3, 3), # Input Channels - 160\n",
    "                                               expansion_factor=6) # Output Channels 320, stride = 1\n",
    "        \n",
    "        \n",
    "        # Layer - 19, Inverted Residuals and Linear Bottlenecks\n",
    "        self.conv2 = Convolution2D(1280, (1, 1), (1, 1), \"SAME\")\n",
    "        self.conf_head_layers = create_conf_head_layers(self.num_outputs)\n",
    "        self.loc_head_layers = create_loc_head_layers()\n",
    "   \n",
    "    def compute_heads(self, x, idx):\n",
    "        \"\"\" Compute outputs of classification and regression heads\n",
    "        Args:\n",
    "            x: the input feature map\n",
    "            idx: index of the head layer\n",
    "        Returns:\n",
    "            conf: output of the idx-th classification head\n",
    "            loc: output of the idx-th regression head\n",
    "        \"\"\"\n",
    "        global conff\n",
    "        for layr in self.conf_head_layers[idx]:\n",
    "            x= layr(x)\n",
    "        conf=x\n",
    "        mul=conf.shape[1]*conf.shape[2]*6\n",
    "        conf = tf.reshape(conf, [-1,mul, self.num_outputs])\n",
    "        for layr in self.loc_head_layers[idx]:\n",
    "            x=layr(x)\n",
    "        \n",
    "        loc = x\n",
    "        loc = tf.reshape(loc, [-1, mul, 4])\n",
    "\n",
    "        return conf, loc\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs,training=True):\n",
    "        confs=[]\n",
    "        locs=[]\n",
    "        print(training)\n",
    "        # Layer - 1, 2D Conv - Channels (3 -> 32)\n",
    "        x = self.conv1(inputs,training)\n",
    "        #print(\"Shape 0 check\")\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.exp1(x,training)\n",
    "        #print(\"Shape 1 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp2(x,training)\n",
    "        #print(\"Shape 2 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp3(x,training)\n",
    "        #print(\"Shape 3 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp4(x,training)\n",
    "        #print(\"Shape 4 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp5(x,training)\n",
    "        #print(\"Shape 5 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp6(x,training)\n",
    "        x = self.exp7(x,training)\n",
    "        #print(\"Shape 7 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp8(x,training)\n",
    "        #print(\"Shape 8 check\")\n",
    "        #print(x)\n",
    "        x = self.exp9(x,training)\n",
    "        #print(\"Shape 9 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp10(x,training)\n",
    "        #print(\"Shape 10 check\")\n",
    "        #print(x.shape)\n",
    "        x = self.exp11(x,training)\n",
    "        x = self.exp12(x,training)\n",
    "        x = self.exp13(x,training)\n",
    "        x = self.exp14(x,training)\n",
    "        \n",
    "        #y=tf.reshape(x, [x.shape[0],-1, 10])\n",
    "        #print(y.shape)\n",
    "        x = self.exp15(x,training)\n",
    "        #print(x.shape)\n",
    "        #print(\"exp_15.shape----->\",x.shape)\n",
    "        conf, loc = self.compute_heads(self.batch_norm(x,training), 0)\n",
    "        confs.append(conf)\n",
    "        locs.append(loc)\n",
    "        x=self.exp16(x)\n",
    "        x=self.exp17(x)\n",
    "        x=self.conv2(x)\n",
    "        #print(\"conv2.shape--------->\",x.shape)\n",
    "        conf, loc = self.compute_heads(self.batch_norm_1(x,training), 1)\n",
    "        confs.append(conf)\n",
    "        locs.append(loc)\n",
    "        confs = tf.concat(confs, axis=1)\n",
    "        locs = tf.concat(locs, axis=1)\n",
    "        \n",
    "        return confs,locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample(Model):\n",
    "    \n",
    "    def __init__(self, num_outputs):\n",
    "        super(sample, self).__init__()\n",
    "        self.num_outputs=num_outputs\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = Convolution2D(32, (3, 3), (2, 2), \"SAME\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        # Layer - 1, 2D Conv - Channels (3 -> 32)\n",
    "        x = self.conv1(inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dummy Data to set the inputs\n",
    "s = (1, 300, 300, 3)\n",
    "nx = np.random.rand(*s).astype(np.float32)/ 255\n",
    "print(nx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dui\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# # MobilenetV2 Model Object\n",
    "# num_outputs = 21 # Output Channels\n",
    "# m2 = MobilenetV2(num_outputs)\n",
    "# m2._set_inputs(nx,training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_norm (BatchNorm)       multiple                  640       \n",
      "_________________________________________________________________\n",
      "batch_norm_1 (BatchNorm)     multiple                  5120      \n",
      "_________________________________________________________________\n",
      "convolution2d (Convolution2D multiple                  1024      \n",
      "_________________________________________________________________\n",
      "expanded_convolution (Expand multiple                  1040      \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride2 multiple                  5400      \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  9192      \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride2 multiple                  10384     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  15328     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  15328     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride2 multiple                  21632     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  55232     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  55232     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  55232     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_diff (E multiple                  67680     \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  119712    \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  119712    \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride2 multiple                  156896    \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  322400    \n",
      "_________________________________________________________________\n",
      "expanded_convolution_stride1 multiple                  322400    \n",
      "_________________________________________________________________\n",
      "expanded_convolution_diff_1  multiple                  476800    \n",
      "_________________________________________________________________\n",
      "convolution2d_18 (Convolutio multiple                  416000    \n",
      "_________________________________________________________________\n",
      "convolution2d_19 (Convolutio multiple                  182070    \n",
      "_________________________________________________________________\n",
      "depthwise_convolution_17 (De multiple                  1764      \n",
      "_________________________________________________________________\n",
      "convolution2d_20 (Convolutio multiple                  161910    \n",
      "_________________________________________________________________\n",
      "convolution2d_21 (Convolutio multiple                  27336     \n",
      "_________________________________________________________________\n",
      "depthwise_convolution_18 (De multiple                  336       \n",
      "_________________________________________________________________\n",
      "convolution2d_22 (Convolutio multiple                  3144      \n",
      "=================================================================\n",
      "Total params: 2,628,944\n",
      "Trainable params: 2,605,260\n",
      "Non-trainable params: 23,684\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "INFO:tensorflow:Assets written to: save/ssd_saving/assets\n"
     ]
    }
   ],
   "source": [
    "# m2.save(\"save/ssd_saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2235400770d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'my_saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    868\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     signatures = signature_serialization.find_function_to_export(\n\u001b[0;32m--> 870\u001b[0;31m         checkpoint_graph_view)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# If the user did not specify signatures, check the root object for a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;31m# that can be made into a signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SIGNATURE_ATTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0;32m--> 141\u001b[0;31m           self._serialization_cache)\n\u001b[0m\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   2420\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 2422\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     return (self._get_serialized_attributes(\n\u001b[0;32m---> 79\u001b[0;31m         serialization_cache).functions_to_serialize)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_serialized_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 94\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     51\u001b[0m     objects, functions = (\n\u001b[1;32m     52\u001b[0m         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\n\u001b[0;32m---> 53\u001b[0;31m             serialization_cache))\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mfunctions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_default_save_signature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Attribute validator requires that the default save signature is added to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# function dict, even if the value is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;31m# Reset the losses of the layer and its children. The call function in each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# child layer is replaced with tf.functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0moriginal_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_child_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36m_replace_child_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    246\u001b[0m       layer_fns = (\n\u001b[1;32m    247\u001b[0m           child_layer._trackable_saved_model_saver._get_serialized_attributes(\n\u001b[0;32m--> 248\u001b[0;31m               serialization_cache).functions)\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m       layer_fns = (\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 94\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Attribute validator requires that the default save signature is added to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# function dict, even if the value is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    164\u001b[0m   call_fn_with_losses = call_collection.add_function(\n\u001b[1;32m    165\u001b[0m       \u001b[0m_wrap_call_and_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       '{}_layer_call_and_return_conditional_losses'.format(layer.name))\n\u001b[0m\u001b[1;32m    167\u001b[0m   call_fn = call_collection.add_function(\n\u001b[1;32m    168\u001b[0m       \u001b[0m_extract_outputs_from_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_fn_with_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36madd_function\u001b[0;34m(self, call_fn, name)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# Manually add traces for layers that have keyword arguments and have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# a fully defined input signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36madd_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mtrace_with_training\u001b[0;34m(value, fn)\u001b[0m\n\u001b[1;32m    409\u001b[0m           \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayerCall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         saving=True):\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         lambda: replace_training_and_call(False))\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall_and_return_conditional_losses\u001b[0;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0mlayer_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_layer_call_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_losses_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_create_call_fn_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreturn_outputs_and_add_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         lambda: replace_training_and_call(False))\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayerCall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36madd_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mtrace_with_training\u001b[0;34m(value, fn)\u001b[0m\n\u001b[1;32m    409\u001b[0m           \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mtrace_with_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayerCall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m       \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                            (str(args), str(self.input_signature)))\n\u001b[1;32m   1890\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m       \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         saving=True):\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         lambda: replace_training_and_call(False))\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     return tf_utils.smart_cond(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall_and_return_conditional_losses\u001b[0;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0mlayer_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_layer_call_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_losses_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_create_call_fn_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: call() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# tf.saved_model.save(m2,'my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting input shape for the model\n",
    "# # Setting input shapes manually, as we are not calling model.fit\n",
    "# c,f=m2(nx)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ssd(num_classes,\n",
    "               checkpoint_dir=None,\n",
    "               checkpoint_path=None):\n",
    "    \"\"\" Create SSD model and load pretrained weights\n",
    "    Args:\n",
    "        num_classes: number of classes\n",
    "        pretrained_type: type of pretrained weights, can be either 'VGG16' or 'ssd'\n",
    "        weight_path: path to pretrained weights\n",
    "    Returns:\n",
    "        net: the SSD model\n",
    "    \"\"\"\n",
    "    net = MobilenetV2(num_classes)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dui\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1200, 21]), TensorShape([1, 1200, 4]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ss=create_ssd(21)\n",
    "# locs,confs=ss(nx)\n",
    "# locs.shape,confs.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def generate_default_boxes(config):\n",
    "    \"\"\" Generate default boxes for all feature maps\n",
    "    Args:\n",
    "        config: information of feature maps\n",
    "            scales: boxes' size relative to image's size\n",
    "            fm_sizes: sizes of feature maps\n",
    "            ratios: box ratios used in each feature maps\n",
    "    Returns:\n",
    "        default_boxes: tensor of shape (num_default, 4)\n",
    "                       with format (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    default_boxes = []\n",
    "    scales = config['SSD']['scales']\n",
    "    fm_sizes = config['SSD']['fm_sizes']\n",
    "    ratios = config['SSD']['ratios']\n",
    "    \n",
    "    for m, fm_size in enumerate(fm_sizes):\n",
    "        \n",
    "        for i, j in itertools.product(range(fm_size), repeat=2):\n",
    "            k=0\n",
    "#             print(i,j,fm_size)\n",
    "            cx = (j + 0.5) / fm_size\n",
    "            cy = (i + 0.5) / fm_size\n",
    "            default_boxes.append([\n",
    "                cx,\n",
    "                cy,\n",
    "                math.sqrt(scales[0] * scales[1]),\n",
    "                math.sqrt(scales[0] * scales[1])\n",
    "                ])\n",
    "            k+=1\n",
    "            for ratio in ratios[m]:\n",
    "                r = math.sqrt(ratio)\n",
    "                default_boxes.append([\n",
    "                    cx,\n",
    "                    cy,\n",
    "                    scales[m] * r,\n",
    "                    scales[m] / r\n",
    "                ])\n",
    "                k+=1\n",
    "#             print(k)\n",
    "\n",
    "    default_boxes = tf.constant(default_boxes)\n",
    "    default_boxes = tf.clip_by_value(default_boxes, 0.0, 1.0)\n",
    "#     print(\"default_boxes---------------------->\",default_boxes.shape)\n",
    "    return default_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def compute_area(top_left, bot_right):\n",
    "    \"\"\" Compute area given top_left and bottom_right coordinates\n",
    "    Args:\n",
    "        top_left: tensor (num_boxes, 2)\n",
    "        bot_right: tensor (num_boxes, 2)\n",
    "    Returns:\n",
    "        area: tensor (num_boxes,)\n",
    "    \"\"\"\n",
    "    # top_left: N x 2\n",
    "    # bot_right: N x 2\n",
    "    hw = tf.clip_by_value(bot_right - top_left, 0.0, 512.0)\n",
    "    area = hw[..., 0] * hw[..., 1]\n",
    "\n",
    "    return area\n",
    "\n",
    "\n",
    "def compute_iou(boxes_a, boxes_b):\n",
    "    \"\"\" Compute overlap between boxes_a and boxes_b\n",
    "    Args:\n",
    "        boxes_a: tensor (num_boxes_a, 4)\n",
    "        boxes_b: tensor (num_boxes_b, 4)\n",
    "    Returns:\n",
    "        overlap: tensor (num_boxes_a, num_boxes_b)\n",
    "    \"\"\"\n",
    "    # boxes_a => num_boxes_a, 1, 4\n",
    "#     print(\"box_a\",boxes_a.shape,\"box_b\",boxes_b.shape)\n",
    "    boxes_a = tf.expand_dims(boxes_a, 1)\n",
    "\n",
    "    # boxes_b => 1, num_boxes_b, 4\n",
    "#     print(\"transformed_a--------->\",boxes_a.shape)\n",
    "    boxes_b = tf.expand_dims(boxes_b, 0)\n",
    "#     print(\"transformed_b--------->\",boxes_b.shape)\n",
    "#     print(\"boxes_a[..., :2]-------->\",boxes_a[..., :].shape)\n",
    "#     print(\"boxes_b[..., :2]-------->\",boxes_b[..., :].shape)\n",
    "    top_left = tf.math.maximum(boxes_a[..., :2], boxes_b[..., :2])\n",
    "    bot_right = tf.math.minimum(boxes_a[..., 2:], boxes_b[..., 2:])\n",
    "#     print(\"top_left------------>\",top_left.shape,\"bot_right------>\",bot_right.shape)\n",
    "    overlap_area = compute_area(top_left, bot_right)\n",
    "    area_a = compute_area(boxes_a[..., :2], boxes_a[..., 2:])\n",
    "    area_b = compute_area(boxes_b[..., :2], boxes_b[..., 2:])\n",
    "#     print(\"area_a.shape------->\",area_a.shape,\"area_b.shape--------->\",area_b.shape,\"overlap_area.shape------->\",overlap_area.shape)\n",
    "    overlap = overlap_area / (area_a + area_b - overlap_area)\n",
    "\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def compute_target(default_boxes, gt_boxes, gt_labels, iou_threshold=0.5):\n",
    "    \"\"\" Compute regression and classification targets\n",
    "    Args:\n",
    "        default_boxes: tensor (num_default, 4)\n",
    "                       of format (cx, cy, w, h)\n",
    "        gt_boxes: tensor (num_gt, 4)\n",
    "                  of format (xmin, ymin, xmax, ymax)\n",
    "        gt_labels: tensor (num_gt,)\n",
    "    Returns:\n",
    "        gt_confs: classification targets, tensor (num_default,)\n",
    "        gt_locs: regression targets, tensor (num_default, 4)\n",
    "    \"\"\"\n",
    "    # Convert default boxes to format (xmin, ymin, xmax, ymax)\n",
    "    # in order to compute overlap with gt boxes\n",
    "    transformed_default_boxes = transform_center_to_corner(default_boxes)\n",
    "    iou = compute_iou(transformed_default_boxes, gt_boxes)\n",
    "#     print(\"iou--------------->\",iou.shape)\n",
    "    best_gt_iou = tf.math.reduce_max(iou, 1)\n",
    "#     print(\"best_gt_iou----------->\",best_gt_iou.shape) \n",
    "    best_gt_idx = tf.math.argmax(iou, 1)\n",
    "#     print(\"best_gt_idx----------->\",best_gt_idx.shape) #for every anchor best overlap from all the gt\n",
    "    best_default_iou = tf.math.reduce_max(iou, 0)\n",
    "#     print(\"best_default_iou----------->\",best_default_iou.shape)\n",
    "    best_default_idx = tf.math.argmax(iou, 0)\n",
    "#     print(\"best_default_idx----------->\",best_default_idx.shape)  #box of iou for every gt for every anchor\n",
    "#     print(best_default_idx[0],best_gt_idx[best_default_idx[0]])\n",
    "#     best_gt_idx = tf.tensor_scatter_nd_update(\n",
    "#         best_gt_idx,\n",
    "#         tf.expand_dims(best_default_idx, 1),\n",
    "#         tf.range(best_default_idx.shape[0], dtype=tf.int64))\n",
    "#     # Normal way: use a for loop\n",
    "#     # for gt_idx, default_idx in enumerate(best_default_idx):\n",
    "#     #     best_gt_idx = tf.tensor_scatter_nd_update(\n",
    "#     #         best_gt_idx,\n",
    "#     #         tf.expand_dims([default_idx], 1),\n",
    "#     #         [gt_idx])\n",
    "\n",
    "#     best_gt_iou = tf.tensor_scatter_nd_update(\n",
    "#         best_gt_iou,\n",
    "#         tf.expand_dims(best_default_idx, 1),\n",
    "#         tf.ones_like(best_default_idx, dtype=tf.float32))\n",
    "\n",
    "#     print(\"best_gt_iou-------.....................---->\",best_gt_iou.shape)\n",
    "#     print(\"gt_labels-----------_>\",gt_labels)\n",
    "    gt_confs = tf.gather(gt_labels, best_gt_idx)   # gt_class contained in each anchor box\n",
    "#     print(\"gt_confs-----------_>\",gt_confs.shape)\n",
    "    gt_confs = tf.where(\n",
    "        tf.less(best_gt_iou, iou_threshold),\n",
    "        tf.zeros_like(gt_confs),\n",
    "        gt_confs)\n",
    "\n",
    "    gt_boxes = tf.gather(gt_boxes, best_gt_idx)     #gt_boxes (xmin,xmax,ymin,ymax) for each achor \n",
    "    gt_locs = encode(default_boxes, gt_boxes)\n",
    "\n",
    "    return gt_confs, gt_locs\n",
    "\n",
    "\n",
    "def encode(default_boxes, boxes, variance=[0.1, 0.2]):\n",
    "    \"\"\" Compute regression values\n",
    "    Args:\n",
    "        default_boxes: tensor (num_default, 4)\n",
    "                       of format (cx, cy, w, h)\n",
    "        boxes: tensor (num_default, 4)\n",
    "               of format (xmin, ymin, xmax, ymax)\n",
    "        variance: variance for center point and size\n",
    "    Returns:\n",
    "        locs: regression values, tensor (num_default, 4)\n",
    "    \"\"\"\n",
    "    # Convert boxes to (cx, cy, w, h) format\n",
    "    transformed_boxes = transform_corner_to_center(boxes)\n",
    "\n",
    "    locs = tf.concat([\n",
    "        (transformed_boxes[..., :2] - default_boxes[:, :2]\n",
    "         ) / (default_boxes[:, 2:] * variance[0]),\n",
    "        tf.math.log(transformed_boxes[..., 2:] / default_boxes[:, 2:]) / variance[1]],\n",
    "        axis=-1)\n",
    "\n",
    "    return locs\n",
    "\n",
    "\n",
    "def decode(default_boxes, locs, variance=[0.1, 0.2]):\n",
    "    \"\"\" Decode regression values back to coordinates\n",
    "    Args:\n",
    "        default_boxes: tensor (num_default, 4)\n",
    "                       of format (cx, cy, w, h)\n",
    "        locs: tensor (batch_size, num_default, 4)\n",
    "              of format (cx, cy, w, h)\n",
    "        variance: variance for center point and size\n",
    "    Returns:\n",
    "        boxes: tensor (num_default, 4)\n",
    "               of format (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    locs = tf.concat([\n",
    "        locs[..., :2] * variance[0] *\n",
    "        default_boxes[:, 2:] + default_boxes[:, :2],\n",
    "        tf.math.exp(locs[..., 2:] * variance[1]) * default_boxes[:, 2:]], axis=-1)\n",
    "\n",
    "    boxes = transform_center_to_corner(locs)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def transform_corner_to_center(boxes):\n",
    "    \"\"\" Transform boxes of format (xmin, ymin, xmax, ymax)\n",
    "        to format (cx, cy, w, h)\n",
    "    Args:\n",
    "        boxes: tensor (num_boxes, 4)\n",
    "               of format (xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        boxes: tensor (num_boxes, 4)\n",
    "               of format (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    center_box = tf.concat([\n",
    "        (boxes[..., :2] + boxes[..., 2:]) / 2,\n",
    "        boxes[..., 2:] - boxes[..., :2]], axis=-1)\n",
    "\n",
    "    return center_box\n",
    "\n",
    "\n",
    "def transform_center_to_corner(boxes):\n",
    "    \"\"\" Transform boxes of format (cx, cy, w, h)\n",
    "        to format (xmin, ymin, xmax, ymax)\n",
    "    Args:\n",
    "        boxes: tensor (num_boxes, 4)\n",
    "               of format (cx, cy, w, h)\n",
    "    Returns:\n",
    "        boxes: tensor (num_boxes, 4)\n",
    "               of format (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    corner_box = tf.concat([\n",
    "        boxes[..., :2] - boxes[..., 2:] / 2,\n",
    "        boxes[..., :2] + boxes[..., 2:] / 2], axis=-1)\n",
    "\n",
    "    return corner_box\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def hard_negative_mining(loss, gt_confs, neg_ratio):\n",
    "    \"\"\" Hard negative mining algorithm\n",
    "        to pick up negative examples for back-propagation\n",
    "        base on classification loss values\n",
    "    Args:\n",
    "        loss: list of classification losses of all default boxes (B, num_default)\n",
    "        gt_confs: classification targets (B, num_default)\n",
    "        neg_ratio: negative / positive ratio\n",
    "    Returns:\n",
    "        pos_idx: positive samples\n",
    "        neg_idx:negative samples\n",
    "    \"\"\"\n",
    "    # loss: B x N\n",
    "    # gt_confs: B x N\n",
    "    pos_idx = gt_confs > 0\n",
    "#     print(\"pos_idx----------------->\",pos_idx)\n",
    "#     print(\"gt_confs.shape----------------->\",gt_confs.shape)\n",
    "    num_pos = tf.reduce_sum(tf.dtypes.cast(pos_idx, tf.int32), axis=1)\n",
    "    num_neg = num_pos * neg_ratio\n",
    "#     print(\"num_neg.shape----------------->\",num_neg.shape)\n",
    "#     print(\"loss.shape\",loss.shape)\n",
    "    rank = tf.argsort(loss, axis=1, direction='DESCENDING')  #boxes having more loss indices sorted desecnding (box numbers)\n",
    "#     print(\"rankk----->\",rank,\"dsasdasdas\")\n",
    "    rank = tf.argsort(rank, axis=1)                          #indices of boxes present where in the array soreted acctoring to index\n",
    "#     print(\"duii------>\",rank.numpy())\n",
    "    neg_idx = rank < tf.expand_dims(num_neg, 1)              \n",
    "#     print(\"neg_idx--------->\",neg_idx)\n",
    "    return pos_idx, neg_idx\n",
    "\n",
    "\n",
    "class SSDLosses(object):\n",
    "    \"\"\" Class for SSD Losses\n",
    "    Attributes:\n",
    "        neg_ratio: negative / positive ratio\n",
    "        num_classes: number of classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, neg_ratio, num_classes):\n",
    "        self.neg_ratio = neg_ratio\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, confs, locs, gt_confs, gt_locs):\n",
    "        \"\"\" Compute losses for SSD\n",
    "            regression loss: smooth L1\n",
    "            classification loss: cross entropy\n",
    "        Args:\n",
    "            confs: outputs of classification heads (B, num_default, num_classes)\n",
    "            locs: outputs of regression heads (B, num_default, 4)\n",
    "            gt_confs: classification targets (B, num_default)\n",
    "            gt_locs: regression targets (B, num_default, 4)\n",
    "        Returns:\n",
    "            conf_loss: classification loss\n",
    "            loc_loss: regression loss\n",
    "        \"\"\"\n",
    "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "        # compute classification losses\n",
    "        # without reduction\n",
    "#         print(confs.shape,gt_confs.shape)\n",
    "        temp_loss = cross_entropy(\n",
    "            gt_confs, confs)\n",
    "        pos_idx, neg_idx = hard_negative_mining(\n",
    "            temp_loss, gt_confs, self.neg_ratio)\n",
    "\n",
    "        # classification loss will consist of positive and negative examples\n",
    "\n",
    "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='sum')\n",
    "        smooth_l1_loss = tf.keras.losses.Huber(reduction='sum')\n",
    "\n",
    "        conf_loss = cross_entropy(\n",
    "            gt_confs[tf.math.logical_or(pos_idx, neg_idx)],\n",
    "            confs[tf.math.logical_or(pos_idx, neg_idx)])\n",
    "\n",
    "        # regression loss only consist of positive examples\n",
    "        loc_loss = smooth_l1_loss(\n",
    "            # tf.boolean_mask(gt_locs, pos_idx),\n",
    "            # tf.boolean_mask(locs, pos_idx))\n",
    "            gt_locs[pos_idx],\n",
    "            locs[pos_idx])\n",
    "\n",
    "        num_pos = tf.reduce_sum(tf.dtypes.cast(pos_idx, tf.float32))\n",
    "#         print(\"loss_function------------>\",conf_loss.numpy(),loc_loss.numpy(),temp_loss.numpy())\n",
    "        conf_loss = conf_loss / num_pos\n",
    "        loc_loss = loc_loss / num_pos\n",
    "\n",
    "        return conf_loss, loc_loss\n",
    "\n",
    "\n",
    "def create_losses(neg_ratio, num_classes):\n",
    "    criterion = SSDLosses(neg_ratio, num_classes)\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "class VOCDataset():\n",
    "    \"\"\" Class for VOC Dataset\n",
    "    Attributes:\n",
    "        root_dir: dataset root dir (ex: ./data/VOCdevkit)\n",
    "        year: dataset's year (2007 or 2012)\n",
    "        num_examples: number of examples to be used\n",
    "                      (in case one wants to overfit small data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, year, default_boxes,\n",
    "                 new_size, num_examples=-1, augmentation=None):\n",
    "        super(VOCDataset, self).__init__()\n",
    "        self.idx_to_name = [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "        self.name_to_idx = dict([(v, k)\n",
    "                                 for k, v in enumerate(self.idx_to_name)])\n",
    "\n",
    "        self.data_dir = os.path.join(root_dir, 'VOC{}'.format(year))\n",
    "        self.image_dir = os.path.join(self.data_dir, 'JPEGImages')\n",
    "        self.anno_dir = os.path.join(self.data_dir, 'Annotations')\n",
    "        self.ids = list(map(lambda x: x[:-4], os.listdir(self.image_dir)))\n",
    "        self.default_boxes = default_boxes\n",
    "        self.new_size = new_size\n",
    "\n",
    "        if num_examples != -1:\n",
    "            self.ids = self.ids[:num_examples]\n",
    "\n",
    "        self.train_ids = self.ids[:int(len(self.ids) * 0.75)]\n",
    "        self.val_ids = self.ids[int(len(self.ids) * 0.75):]\n",
    "\n",
    "        if augmentation == None:\n",
    "            self.augmentation = ['original']\n",
    "        else:\n",
    "            self.augmentation = augmentation + ['original']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def _get_image(self, index):\n",
    "        \"\"\" Method to read image from file\n",
    "            then resize to (300, 300)\n",
    "            then subtract by ImageNet's mean\n",
    "            then convert to Tensor\n",
    "        Args:\n",
    "            index: the index to get filename from self.ids\n",
    "        Returns:\n",
    "            img: tensor of shape (3, 300, 300)\n",
    "        \"\"\"\n",
    "        filename = self.ids[index]\n",
    "        img_path = os.path.join(self.image_dir, filename + '.jpg')\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _get_annotation(self, index, orig_shape):\n",
    "        \"\"\" Method to read annotation from file\n",
    "            Boxes are normalized to image size\n",
    "            Integer labels are increased by 1\n",
    "        Args:\n",
    "            index: the index to get filename from self.ids\n",
    "            orig_shape: image's original shape\n",
    "        Returns:\n",
    "            boxes: numpy array of shape (num_gt, 4)\n",
    "            labels: numpy array of shape (num_gt,)\n",
    "        \"\"\"\n",
    "        h, w = orig_shape\n",
    "        filename = self.ids[index]\n",
    "        anno_path = os.path.join(self.anno_dir, filename + '.xml')\n",
    "        objects = ET.parse(anno_path).findall('object')\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for obj in objects:\n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = (float(bndbox.find('xmin').text) - 1) / w\n",
    "            ymin = (float(bndbox.find('ymin').text) - 1) / h\n",
    "            xmax = (float(bndbox.find('xmax').text) - 1) / w\n",
    "            ymax = (float(bndbox.find('ymax').text) - 1) / h\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            labels.append(self.name_to_idx[name] + 1)\n",
    "\n",
    "        return np.array(boxes, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "    def generate(self, subset=None):\n",
    "        \"\"\" The __getitem__ method\n",
    "            so that the object can be iterable\n",
    "        Args:\n",
    "            index: the index to get filename from self.ids\n",
    "        Returns:\n",
    "            img: tensor of shape (300, 300, 3)\n",
    "            boxes: tensor of shape (num_gt, 4)\n",
    "            labels: tensor of shape (num_gt,)\n",
    "        \"\"\"\n",
    "        if subset == 'train':\n",
    "            indices = self.train_ids\n",
    "        elif subset == 'val':\n",
    "            indices = self.val_ids\n",
    "        else:\n",
    "            indices = self.ids\n",
    "        for index in range(len(indices)):\n",
    "            # img, orig_shape = self._get_image(index)\n",
    "            filename = indices[index]\n",
    "            img = self._get_image(index)\n",
    "            w, h = img.size\n",
    "            boxes, labels = self._get_annotation(index, (h, w))\n",
    "            boxes = tf.constant(boxes, dtype=tf.float32)\n",
    "            labels = tf.constant(labels, dtype=tf.int64)\n",
    "#             print(labels)\n",
    "\n",
    "            augmentation_method = np.random.choice(self.augmentation)\n",
    "            if augmentation_method == 'patch':\n",
    "                img, boxes, labels = random_patching(img, boxes, labels)\n",
    "            elif augmentation_method == 'flip':\n",
    "                img, boxes, labels = horizontal_flip(img, boxes, labels)\n",
    "\n",
    "            img = np.array(img.resize(\n",
    "                (self.new_size, self.new_size)), dtype=np.float32)\n",
    "            img = (img / 127.0) - 1.0\n",
    "            img = tf.constant(img, dtype=tf.float32)\n",
    "\n",
    "            gt_confs, gt_locs = compute_target(\n",
    "                self.default_boxes, boxes, labels)\n",
    "\n",
    "            yield filename, img, gt_confs, gt_locs\n",
    "\n",
    "\n",
    "def create_batch_generator(root_dir, year, default_boxes,\n",
    "                           new_size, batch_size, num_batches,\n",
    "                           mode,\n",
    "                           augmentation=None):\n",
    "    num_examples = batch_size * num_batches if num_batches > 0 else -1\n",
    "    voc = VOCDataset(root_dir, year, default_boxes,\n",
    "                     new_size, num_examples, augmentation)\n",
    "\n",
    "    info = {\n",
    "        'idx_to_name': voc.idx_to_name,\n",
    "        'name_to_idx': voc.name_to_idx,\n",
    "        'length': len(voc),\n",
    "        'image_dir': voc.image_dir,\n",
    "        'anno_dir': voc.anno_dir\n",
    "    }\n",
    "\n",
    "    if mode == 'train':\n",
    "        train_gen = partial(voc.generate, subset='train')\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            train_gen, (tf.string, tf.float32, tf.int64, tf.float32))\n",
    "        val_gen = partial(voc.generate, subset='val')\n",
    "        val_dataset = tf.data.Dataset.from_generator(\n",
    "            val_gen, (tf.string, tf.float32, tf.int64, tf.float32))\n",
    "\n",
    "        train_dataset = train_dataset.shuffle(40).batch(batch_size)\n",
    "        val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "        return train_dataset.take(num_batches), val_dataset.take(-1), info\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            voc.generate, (tf.string, tf.float32, tf.int64, tf.float32))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset.take(num_batches), info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "config={\n",
    "    'SSD':{\n",
    "          'ratios': [[1.0,2.0,0.5,3.0,.333], [1.0,2.0,0.5,3.0,.333]],\n",
    "          'scales': [0.2, 0.95],\n",
    "          'fm_sizes': [10, 10],\n",
    "          'image_size': 300,\n",
    "            },\n",
    "    'batch_size':64,\n",
    "    'data_year':'2007',\n",
    "    'data_dir':\"pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/\",\n",
    "    'num_batches':-1,\n",
    "    'neg_ratio':3,\n",
    "    'initial_lr':1e-3,\n",
    "    'momentum':0.9,\n",
    "    'weight_decay':5e-4,\n",
    "    'num_epochs':120,\n",
    "    'checkpoint_dir':'checkpoints',\n",
    "    'pretrained_type':'base',\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = \"checkpoints/ssd-{epoch:04d}.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_created\n",
      "<__main__.MobilenetV2 object at 0x15d24bf98>\n",
      "0\n",
      "dui\n",
      "True\n",
      "True\n",
      "WARNING:tensorflow:Entity <bound method SSDLosses.__call__ of <__main__.SSDLosses object at 0x157335668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method SSDLosses.__call__ of <__main__.SSDLosses object at 0x157335668>>, which Python reported as:\n",
      "    def __call__(self, confs, locs, gt_confs, gt_locs):\n",
      "        \"\"\" Compute losses for SSD\n",
      "            regression loss: smooth L1\n",
      "            classification loss: cross entropy\n",
      "        Args:\n",
      "            confs: outputs of classification heads (B, num_default, num_classes)\n",
      "            locs: outputs of regression heads (B, num_default, 4)\n",
      "            gt_confs: classification targets (B, num_default)\n",
      "            gt_locs: regression targets (B, num_default, 4)\n",
      "        Returns:\n",
      "            conf_loss: classification loss\n",
      "            loc_loss: regression loss\n",
      "        \"\"\"\n",
      "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='none')\n",
      "\n",
      "        # compute classification losses\n",
      "        # without reduction\n",
      "#         print(confs.shape,gt_confs.shape)\n",
      "        temp_loss = cross_entropy(\n",
      "            gt_confs, confs)\n",
      "        pos_idx, neg_idx = hard_negative_mining(\n",
      "            temp_loss, gt_confs, self.neg_ratio)\n",
      "\n",
      "        # classification loss will consist of positive and negative examples\n",
      "\n",
      "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='sum')\n",
      "        smooth_l1_loss = tf.keras.losses.Huber(reduction='sum')\n",
      "\n",
      "        conf_loss = cross_entropy(\n",
      "            gt_confs[tf.math.logical_or(pos_idx, neg_idx)],\n",
      "            confs[tf.math.logical_or(pos_idx, neg_idx)])\n",
      "\n",
      "        # regression loss only consist of positive examples\n",
      "        loc_loss = smooth_l1_loss(\n",
      "            # tf.boolean_mask(gt_locs, pos_idx),\n",
      "            # tf.boolean_mask(locs, pos_idx))\n",
      "            gt_locs[pos_idx],\n",
      "            locs[pos_idx])\n",
      "\n",
      "        num_pos = tf.reduce_sum(tf.dtypes.cast(pos_idx, tf.float32))\n",
      "#         print(\"loss_function------------>\",conf_loss.numpy(),loc_loss.numpy(),temp_loss.numpy())\n",
      "        conf_loss = conf_loss / num_pos\n",
      "        loc_loss = loc_loss / num_pos\n",
      "\n",
      "        return conf_loss, loc_loss\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method SSDLosses.__call__ of <__main__.SSDLosses object at 0x157335668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method SSDLosses.__call__ of <__main__.SSDLosses object at 0x157335668>>, which Python reported as:\n",
      "    def __call__(self, confs, locs, gt_confs, gt_locs):\n",
      "        \"\"\" Compute losses for SSD\n",
      "            regression loss: smooth L1\n",
      "            classification loss: cross entropy\n",
      "        Args:\n",
      "            confs: outputs of classification heads (B, num_default, num_classes)\n",
      "            locs: outputs of regression heads (B, num_default, 4)\n",
      "            gt_confs: classification targets (B, num_default)\n",
      "            gt_locs: regression targets (B, num_default, 4)\n",
      "        Returns:\n",
      "            conf_loss: classification loss\n",
      "            loc_loss: regression loss\n",
      "        \"\"\"\n",
      "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='none')\n",
      "\n",
      "        # compute classification losses\n",
      "        # without reduction\n",
      "#         print(confs.shape,gt_confs.shape)\n",
      "        temp_loss = cross_entropy(\n",
      "            gt_confs, confs)\n",
      "        pos_idx, neg_idx = hard_negative_mining(\n",
      "            temp_loss, gt_confs, self.neg_ratio)\n",
      "\n",
      "        # classification loss will consist of positive and negative examples\n",
      "\n",
      "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='sum')\n",
      "        smooth_l1_loss = tf.keras.losses.Huber(reduction='sum')\n",
      "\n",
      "        conf_loss = cross_entropy(\n",
      "            gt_confs[tf.math.logical_or(pos_idx, neg_idx)],\n",
      "            confs[tf.math.logical_or(pos_idx, neg_idx)])\n",
      "\n",
      "        # regression loss only consist of positive examples\n",
      "        loc_loss = smooth_l1_loss(\n",
      "            # tf.boolean_mask(gt_locs, pos_idx),\n",
      "            # tf.boolean_mask(locs, pos_idx))\n",
      "            gt_locs[pos_idx],\n",
      "            locs[pos_idx])\n",
      "\n",
      "        num_pos = tf.reduce_sum(tf.dtypes.cast(pos_idx, tf.float32))\n",
      "#         print(\"loss_function------------>\",conf_loss.numpy(),loc_loss.numpy(),temp_loss.numpy())\n",
      "        conf_loss = conf_loss / num_pos\n",
      "        loc_loss = loc_loss / num_pos\n",
      "\n",
      "        return conf_loss, loc_loss\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-81ba09cd1c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         loss, conf_loss, loc_loss, l2_loss = train_step(\n\u001b[0;32m---> 94\u001b[0;31m             imgs, gt_confs, gt_locs, ssd, criterion, optimizer,config)\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mavg_conf_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_conf_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconf_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "NUM_CLASSES = 21\n",
    "\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "@tf.function\n",
    "def train_step(imgs, gt_confs, gt_locs, ssd, criterion, optimizer,config):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #loss_scale = 8\n",
    "        confs, locs = ssd(imgs)\n",
    "        #sys.exit()\n",
    "        #print(confs)\n",
    "        #print(\"gt_confs.shape------------------>\",gt_confs.shape)\n",
    "        #print(\"gt_locs.shape------------------->\",gt_locs.shape)\n",
    "        #print(\"real_confs.shape--------------->\",confs.shape)\n",
    "        #print(\"real_locs.shape---------------_>\",locs.shape)\n",
    "        conf_loss, loc_loss = criterion(\n",
    "            confs, locs, gt_confs, gt_locs)\n",
    "        #conf_loss*=loss_scale\n",
    "        #loc_loss*=loss_scale\n",
    "        #print(\"train_loss---------->\",conf_loss,loc_loss,\"dasdasdadasdas\")\n",
    "        loss = conf_loss + loc_loss\n",
    "        l2_loss = [tf.nn.l2_loss(t) for t in ssd.trainable_variables]\n",
    "        l2_loss = config['weight_decay'] * tf.math.reduce_sum(l2_loss)\n",
    "        loss += l2_loss\n",
    "        #print(\"total_loss.shape------------------>\",loss.shape)\n",
    "    #print(loss.numpy())\n",
    "    gradients = tape.gradient(loss, ssd.trainable_variables)\n",
    "    #gradients/=loss_scale\n",
    "    optimizer.apply_gradients(zip(gradients, ssd.trainable_variables))\n",
    "\n",
    "    return loss, conf_loss, loc_loss, l2_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "default_boxes = generate_default_boxes(config)\n",
    "\n",
    "\n",
    "batch_generator, val_generator, info = create_batch_generator(\n",
    "    config['data_dir'],config['data_year'], default_boxes,\n",
    "    config['SSD']['image_size'],\n",
    "    config['batch_size'],config['num_batches'],\n",
    "    mode='train', augmentation=None)  # the patching algorithm is currently causing bottleneck sometimes\n",
    "# print(\"info_length------------------->\",info['length'])\n",
    "try:\n",
    "    ssd = create_ssd(NUM_CLASSES)\n",
    "    #ssd._set_inputs(nx)\n",
    "    print(\"ssd_created\")\n",
    "    print(ssd)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('The program is exiting...')\n",
    "    sys.exit()\n",
    "\n",
    "criterion = create_losses(config['neg_ratio'], NUM_CLASSES)\n",
    "\n",
    "steps_per_epoch = info['length'] // config['batch_size']\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "lr_fn = PiecewiseConstantDecay(\n",
    "    boundaries=[int(steps_per_epoch * config['num_epochs'] * 2 / 3),\n",
    "                int(steps_per_epoch * config['num_epochs'] * 5 / 6)],\n",
    "    values=[config['initial_lr'],config['initial_lr'] * 0.1, config['initial_lr'] * 0.01])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=lr_fn,\n",
    "    momentum=config['momentum'])\n",
    "\n",
    "\n",
    "\n",
    "train_log_dir = 'logs/train'\n",
    "val_log_dir = 'logs/val'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    avg_loss = 0.0\n",
    "    avg_conf_loss = 0.0\n",
    "    avg_loc_loss = 0.0\n",
    "    start = time.time()\n",
    "    \n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(batch_generator):\n",
    "        #print(gt_confs.shape,imgs.shape)\n",
    "        print(i)\n",
    "        #sys.exit()\n",
    "        #ssd(imgs)\n",
    "        \n",
    "        \n",
    "        loss, conf_loss, loc_loss, l2_loss = train_step(\n",
    "            imgs, gt_confs, gt_locs, ssd, criterion, optimizer,config)\n",
    "        avg_loss = (avg_loss * i + loss.numpy()) / (i + 1)\n",
    "        avg_conf_loss = (avg_conf_loss * i + conf_loss.numpy()) / (i + 1)\n",
    "        avg_loc_loss = (avg_loc_loss * i + loc_loss.numpy()) / (i + 1)\n",
    "        #print(\"train------------------------_________>\",avg_loss,avg_conf_loss,avg_loc_loss)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print('Epoch: {} Batch {} Time: {:.2}s | Loss: {:.4f} Conf: {:.4f} Loc: {:.4f}'.format(\n",
    "                epoch + 1, i + 1, time.time() - start, avg_loss, avg_conf_loss, avg_loc_loss))\n",
    "#         ssd.save_weights(checkpoint_path.format(epoch=epoch))\n",
    "    avg_val_loss = 0.0\n",
    "    avg_val_conf_loss = 0.0\n",
    "    avg_val_loc_loss = 0.0\n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(val_generator):\n",
    "        val_confs, val_locs = ssd(imgs)\n",
    "        val_conf_loss, val_loc_loss = criterion(\n",
    "            val_confs, val_locs, gt_confs, gt_locs)\n",
    "        val_loss = val_conf_loss + val_loc_loss\n",
    "        avg_val_loss = (avg_val_loss * i + val_loss.numpy()) / (i + 1)\n",
    "        avg_val_conf_loss = (avg_val_conf_loss * i + val_conf_loss.numpy()) / (i + 1)\n",
    "        avg_val_loc_loss = (avg_val_loc_loss * i + val_loc_loss.numpy()) / (i + 1)\n",
    "\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', avg_loss, step=epoch)\n",
    "        tf.summary.scalar('conf_loss', avg_conf_loss, step=epoch)\n",
    "        tf.summary.scalar('loc_loss', avg_loc_loss, step=epoch)\n",
    "\n",
    "    with val_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', avg_val_loss, step=epoch)\n",
    "        tf.summary.scalar('conf_loss', avg_val_conf_loss, step=epoch)\n",
    "        tf.summary.scalar('loc_loss', avg_val_loc_loss, step=epoch)\n",
    "#     print(epoch)\n",
    "    ssd.save_weights(checkpoint_path.format(epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 300, 300, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dui\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=154995, shape=(1, 1200, 21), dtype=float16, numpy=\n",
       " array([[[-0.008766,  0.12494 , -0.02861 , ...,  0.04688 ,  0.0807  ,\n",
       "          -0.01249 ],\n",
       "         [-0.04407 ,  0.01852 ,  0.01244 , ..., -0.0806  ,  0.04407 ,\n",
       "           0.03032 ],\n",
       "         [ 0.05978 ,  0.01834 , -0.0398  , ...,  0.1605  , -0.05032 ,\n",
       "          -0.01039 ],\n",
       "         ...,\n",
       "         [ 0.04166 ,  0.10443 , -0.5767  , ...,  0.02562 ,  0.00823 ,\n",
       "          -0.2329  ],\n",
       "         [-0.3904  , -0.0211  , -0.328   , ...,  0.05948 , -0.4636  ,\n",
       "          -0.1831  ],\n",
       "         [-0.1669  , -0.153   , -0.629   , ..., -0.2288  ,  0.442   ,\n",
       "           0.1295  ]]], dtype=float16)>,\n",
       " <tf.Tensor: id=154996, shape=(1, 1200, 4), dtype=float16, numpy=\n",
       " array([[[ 1.357e-02,  3.507e-04,  5.802e-03,  2.544e-02],\n",
       "         [ 6.344e-03, -2.820e-04,  5.292e-02,  2.988e-02],\n",
       "         [-2.195e-03, -4.613e-04, -9.827e-03,  2.690e-02],\n",
       "         ...,\n",
       "         [-8.032e-01,  4.192e-01, -1.440e-01,  2.499e-01],\n",
       "         [-8.984e-02,  1.564e-01, -4.114e-01, -3.770e-01],\n",
       "         [ 6.328e-01, -6.230e-01,  4.766e-01, -2.401e-01]]], dtype=float16)>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd = MobilenetV2(21)\n",
    "ssd._set_inputs(nx,training=False)\n",
    "ssd(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x18c49da20>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd.load_weights(\"checkpoints/ssd-0000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=229950, shape=(1, 1200, 21), dtype=float16, numpy=\n",
       " array([[[ 3.0589e-04, -1.7607e-04, -2.0468e-04, ..., -1.9634e-04,\n",
       "          -7.5996e-05, -4.6015e-05],\n",
       "         [ 1.4901e-04, -2.3520e-04, -1.0574e-04, ..., -2.5928e-05,\n",
       "           5.5790e-05, -1.4961e-05],\n",
       "         [ 1.0979e-04,  9.7215e-05,  1.0729e-06, ...,  4.7684e-07,\n",
       "           3.8266e-04,  1.5736e-04],\n",
       "         ...,\n",
       "         [ 3.7140e-02, -3.7231e-03, -3.5620e-04, ...,  4.4250e-04,\n",
       "           1.3895e-03, -1.6174e-03],\n",
       "         [ 4.0955e-02, -3.4580e-03, -5.1041e-03, ..., -3.8280e-03,\n",
       "           1.2197e-03,  9.9182e-04],\n",
       "         [ 4.7424e-02, -4.8065e-03, -4.1237e-03, ..., -6.0987e-04,\n",
       "          -8.5754e-03, -5.3368e-03]]], dtype=float16)>,\n",
       " <tf.Tensor: id=229951, shape=(1, 1200, 4), dtype=float16, numpy=\n",
       " array([[[ 1.1539e-04, -1.5378e-05, -4.9543e-04,  1.0395e-03],\n",
       "         [ 1.6582e-04, -7.9930e-05, -1.1295e-04,  2.7108e-04],\n",
       "         [-8.8274e-05,  3.6955e-06, -3.2783e-06,  5.8651e-05],\n",
       "         ...,\n",
       "         [ 9.2316e-03, -7.6065e-03,  3.5114e-03, -1.6846e-02],\n",
       "         [ 6.5651e-03, -2.1622e-02, -1.2932e-02, -8.1711e-03],\n",
       "         [-7.5877e-05,  4.4098e-03, -1.2077e-02,  7.2098e-03]]],\n",
       "       dtype=float16)>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd(nx,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/ssd-{epoch:04d}.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path.format(epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd._set_inputs(nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "ssd.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=tf.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    ssd, to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install python-pydot python-pydot-ng graphviz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to be traced.\n",
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def my_func(x, y):\n",
    "  # A simple hand-rolled layer.\n",
    "  return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "# Set up logging.\n",
    "# stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = 'logs/new'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Sample data for your function.\n",
    "x = tf.random.uniform((3, 3))\n",
    "y = tf.random.uniform((3, 3))\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "# Call only one tf.function when tracing.\n",
    "z = my_func(x, y)\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir logs/new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Data to set the inputs\n",
    "s = (None, 300, 300, 3)\n",
    "nx = np.random.rand(*s).astype(np.float32)/ 255\n",
    "print(nx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_tensor=tf.convert_to_tensor(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.autograph.to_code(train_step.python_function))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=tf.compat.v1.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.name for n in g.as_graph_def().node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ssd.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=229638, shape=(1, 1200, 21), dtype=float16, numpy=\n",
       " array([[[ 3.0589e-04, -1.7607e-04, -2.0468e-04, ..., -1.9634e-04,\n",
       "          -7.5996e-05, -4.6015e-05],\n",
       "         [ 1.4901e-04, -2.3520e-04, -1.0574e-04, ..., -2.5928e-05,\n",
       "           5.5790e-05, -1.4961e-05],\n",
       "         [ 1.0979e-04,  9.7215e-05,  1.0729e-06, ...,  4.7684e-07,\n",
       "           3.8266e-04,  1.5736e-04],\n",
       "         ...,\n",
       "         [ 3.7140e-02, -3.7231e-03, -3.5620e-04, ...,  4.4250e-04,\n",
       "           1.3895e-03, -1.6174e-03],\n",
       "         [ 4.0955e-02, -3.4580e-03, -5.1041e-03, ..., -3.8280e-03,\n",
       "           1.2197e-03,  9.9182e-04],\n",
       "         [ 4.7424e-02, -4.8065e-03, -4.1237e-03, ..., -6.0987e-04,\n",
       "          -8.5754e-03, -5.3368e-03]]], dtype=float16)>,\n",
       " <tf.Tensor: id=229639, shape=(1, 1200, 4), dtype=float16, numpy=\n",
       " array([[[ 1.1539e-04, -1.5378e-05, -4.9543e-04,  1.0395e-03],\n",
       "         [ 1.6582e-04, -7.9930e-05, -1.1295e-04,  2.7108e-04],\n",
       "         [-8.8274e-05,  3.6955e-06, -3.2783e-06,  5.8651e-05],\n",
       "         ...,\n",
       "         [ 9.2316e-03, -7.6065e-03,  3.5114e-03, -1.6846e-02],\n",
       "         [ 6.5651e-03, -2.1622e-02, -1.2932e-02, -8.1711e-03],\n",
       "         [-7.5877e-05,  4.4098e-03, -1.2077e-02,  7.2098e-03]]],\n",
       "       dtype=float16)>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=156809, shape=(1, 1200, 21), dtype=float16, numpy=\n",
       " array([[[ 2.2900e-04, -2.0850e-04, -4.1509e-04, ..., -3.4237e-04,\n",
       "          -1.1265e-05, -3.8326e-05],\n",
       "         [ 1.7977e-04, -3.5787e-04, -1.9622e-04, ...,  7.4863e-05,\n",
       "           3.6359e-06, -1.2696e-04],\n",
       "         [ 1.2386e-04,  1.5986e-04,  1.0663e-04, ...,  6.6042e-05,\n",
       "           4.3201e-04,  2.1112e-04],\n",
       "         ...,\n",
       "         [ 3.6804e-02, -3.7956e-03, -3.3545e-04, ...,  3.7003e-04,\n",
       "           1.4353e-03, -1.5697e-03],\n",
       "         [ 4.0527e-02, -3.3474e-03, -4.8294e-03, ..., -3.8719e-03,\n",
       "           1.2665e-03,  1.1597e-03],\n",
       "         [ 4.6936e-02, -4.3602e-03, -3.7689e-03, ..., -1.0490e-03,\n",
       "          -8.5144e-03, -5.0468e-03]]], dtype=float16)>,\n",
       " <tf.Tensor: id=156810, shape=(1, 1200, 4), dtype=float16, numpy=\n",
       " array([[[ 1.6153e-04,  5.0485e-05, -5.0831e-04,  1.0061e-03],\n",
       "         [ 1.3971e-04, -1.0729e-04, -9.9063e-05,  8.3148e-05],\n",
       "         [-1.8811e-04, -1.1027e-04,  5.8055e-05,  6.2585e-05],\n",
       "         ...,\n",
       "         [ 9.4833e-03, -7.7629e-03,  3.1071e-03, -1.6251e-02],\n",
       "         [ 6.5727e-03, -2.1500e-02, -1.2466e-02, -8.1482e-03],\n",
       "         [-1.2434e-04,  4.2877e-03, -1.2161e-02,  7.3357e-03]]],\n",
       "       dtype=float16)>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(nx,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=147199, shape=(1, 1200, 21), dtype=float16, numpy=\n",
       " array([[[-0.109    ,  0.0349   , -0.0568   , ..., -0.03485  ,\n",
       "          -0.0671   , -0.0012045],\n",
       "         [ 0.03784  ,  0.05133  , -0.129    , ..., -0.0569   ,\n",
       "           0.1407   , -0.014114 ],\n",
       "         [ 0.06866  , -0.006298 ,  0.02832  , ..., -0.05695  ,\n",
       "           0.1198   , -0.01416  ],\n",
       "         ...,\n",
       "         [ 0.2346   ,  0.03177  ,  0.295    , ...,  0.01252  ,\n",
       "           0.2029   ,  0.393    ],\n",
       "         [-0.02768  ,  0.2288   ,  0.1674   , ..., -0.721    ,\n",
       "          -0.1643   ,  0.3054   ],\n",
       "         [-0.382    ,  0.8286   ,  0.3254   , ..., -0.6006   ,\n",
       "           0.389    , -0.0821   ]]], dtype=float16)>,\n",
       " <tf.Tensor: id=147200, shape=(1, 1200, 4), dtype=float16, numpy=\n",
       " array([[[-0.010345,  0.001681,  0.0265  ,  0.002834],\n",
       "         [ 0.02623 , -0.008415,  0.02058 , -0.02312 ],\n",
       "         [ 0.001433, -0.02116 , -0.0313  ,  0.00816 ],\n",
       "         ...,\n",
       "         [-0.409   , -0.4817  , -0.2477  ,  0.3354  ],\n",
       "         [-0.9956  , -0.11646 ,  1.166   ,  0.689   ],\n",
       "         [-0.613   ,  0.1096  , -0.0851  ,  0.3877  ]]], dtype=float16)>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
